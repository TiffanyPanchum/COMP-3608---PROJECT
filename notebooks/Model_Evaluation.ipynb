{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "BASE_PATH = '/workspace/COMP-3608---PROJECT'\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
    "MODELS_PATH = os.path.join(BASE_PATH, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "if not os.path.exists(MODELS_PATH):\n",
    "    os.makedirs(MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot ROC curve\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate and compare models\n",
    "def evaluate_models(X_train, X_test, y_train, y_test, dataset_name):\n",
    "    # Create models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{'-'*50}\")\n",
    "        print(f\"Training and evaluating {name} on {dataset_name} dataset\")\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'model': model,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_prob\n",
    "        }\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"\\nModel: {name}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        # Print classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plot_confusion_matrix(cm, ['Negative', 'Positive'], f'Confusion Matrix - {name} ({dataset_name})')\n",
    "        \n",
    "        # ROC Curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plot_roc_curve(fpr, tpr, roc_auc, f'ROC Curve - {name} ({dataset_name})')\n",
    "        \n",
    "        # Save model\n",
    "        model_filename = os.path.join(MODELS_PATH, f\"{dataset_name}_{name.replace(' ', '_').lower()}.pkl\")\n",
    "        joblib.dump(model, model_filename)\n",
    "        print(f\"Model saved to {model_filename}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to prepare data for modeling\n",
    "def prepare_data_for_modeling(df, target_column, categorical_cols=None, numerical_cols=None):\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    if numerical_cols is None:\n",
    "        numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Remove target from feature lists if present\n",
    "    if target_column in categorical_cols:\n",
    "        categorical_cols.remove(target_column)\n",
    "    if target_column in numerical_cols:\n",
    "        numerical_cols.remove(target_column)\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    # Split data\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    return X_train_processed, X_test_processed, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIABETES DATASET EVALUATION\n",
    "print(\"Loading Diabetes Dataset...\")\n",
    "diabetes_df = pd.read_csv(os.path.join(DATA_PATH, 'feature_engineering/diabetes_feature_engineering'))\n",
    "\n",
    "# Define categorical and numerical columns for diabetes\n",
    "diabetes_cat_cols = ['gender', 'smoking_history', 'age_group', 'bmi_category', 'glucose_tolerance']\n",
    "diabetes_num_cols = [col for col in diabetes_df.columns if col not in diabetes_cat_cols + ['diabetes']]\n",
    "\n",
    "# Prepare data\n",
    "X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = prepare_data_for_modeling(\n",
    "    diabetes_df, 'diabetes', diabetes_cat_cols, diabetes_num_cols)\n",
    "\n",
    "# Evaluate models\n",
    "diabetes_results = evaluate_models(X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes, 'diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. STROKE DATASET EVALUATION\n",
    "print(\"\\nLoading Stroke Dataset...\")\n",
    "stroke_df = pd.read_csv(os.path.join(DATA_PATH, 'feature_engineering/Stroke_feature_engineering'))\n",
    "\n",
    "# For stroke dataset, many columns are already one-hot encoded\n",
    "stroke_cat_cols = ['glucose_risk']\n",
    "stroke_num_cols = [col for col in stroke_df.columns \n",
    "                  if col not in stroke_cat_cols + ['stroke', 'age_group'] \n",
    "                  and not col.startswith('gender_') \n",
    "                  and not col.startswith('ever_married_')\n",
    "                  and not col.startswith('work_type_')\n",
    "                  and not col.startswith('Residence_type_')\n",
    "                  and not col.startswith('smoking_status_')]\n",
    "\n",
    "# Prepare data\n",
    "X_train_stroke, X_test_stroke, y_train_stroke, y_test_stroke = prepare_data_for_modeling(\n",
    "    stroke_df, 'stroke', stroke_cat_cols, stroke_num_cols)\n",
    "\n",
    "# Evaluate models\n",
    "stroke_results = evaluate_models(X_train_stroke, X_test_stroke, y_train_stroke, y_test_stroke, 'stroke')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
